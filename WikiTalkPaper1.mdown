[Ex Machina: Personal Attacks Seen at Scale](https://arxiv.org/pdf/1610.08914.pdf)


## Abstract
develop and illustrate a method that combines crowdsourcing and machine learning to analyze personal attacks at scale

## Method

* crowdsourcing a small fraction of the corpus, labelling each comment according to whther it is a personal attact or not
* train a simple ml classifier (character-level n-gram model), using empirical distribution of human rating (not majority vote)
* the classifier is then used to annotate the entire corpus of comments
* **conclusion** classifier is as good at generating labels as aggregating the judgments of 3 crowd-workers.

## Data 

1. generating a corpus of Wikipedia discussion comments, 
2. choosing a question for eliciting human judgments,
3. selecting a subset of the discussion corpus to label,
4. designing a strategy for eliciting reliable labels.

* 63M comments from discussions relating to user pages and articles dating from 2004-2015.
* The question we posed to get human judgments on whether a comment contains a personal attack is shown in Figure 2.
* to elicit if the attack has a target or whether the comment quotes a previous attack

### Data Quality 
* Each annotator was required to pass a test of 10 questions (threholds for him to pass)
* each comment was labeled by 10+ annotators
* quality evaluated by inter-annotator aggrement
    -  This technique measures whether a set of “common instructions to different observers of the same set of phenomena, yields the same data within a tolerable mar- gin of error”
    -  the data achieves a Krippendorf’s alpha score of 0.45

## Model

* explored Logistic Regression, MLP, plan to use LSTM
* bag of words representation based on word/character-level n-gram
* final softmax layer and cross-entropy loss function
* the set of annotators per comment naturally forms an approximate emporical distribution over opinions of whether the comment is an attact
    - use probability of being classified as xxx instead of binary 
    - both are used still

Two models (LR, **MLP**)
n-gram type (word, **char**)
label type (OH, **ED**)

high in AUC, and Spearman
running our model over the full history of comments in Wikipedia is as good as having each comment labeled by 3 annotators.

* pick the point that strikes a balance be- tween precision and recall on random evaluation data
* the es- timated rate of attacks computed using model-generated labels lies within a 95% confidence interval for the rate of attacks computed from crowd-generated labels.
* at the equal-error threshold, our algo- rithm has a precision of 0.63

## Analysis
[**Code**](https://github.com/ewulczyn/wiki-detox/blob/master/src/figshare/Wikipedia%20Talk%20Data%20-%20Getting%20Started.ipynb)

#Additional Notes

* Personal attacks on Wikipedia talk pages is around 1%

* Crowdsourcing as a data collection method- ology is well studied ([2], [24]) and has proven effective for con- structing corpora for machine learning in various contexts ([3], [13], [18], [21], [27]).

[One](https://www.cs.cmu.edu/~diyiy/docs/icwsm_wiki_15.pdf)
[Another](https://pdfs.semanticscholar.org/1a48/d77b45824cc1982abfa7750f84f3079e930b.pdf)







